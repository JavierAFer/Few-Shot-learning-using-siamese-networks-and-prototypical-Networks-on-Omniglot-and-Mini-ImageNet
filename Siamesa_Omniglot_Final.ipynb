{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aM31vmKR5iVW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import multiprocessing as mp\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Activation, Input\n",
        "from tensorflow.keras.layers import BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.utils import shuffle\n",
        "import numpy.random as rng\n",
        "from tqdm.notebook import tnrange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para facilitar la ejecución del codigo, se descargan directamente los conjuntos de datos y se descomprimen los .zip.\n",
        "\n",
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\n",
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip\n",
        "\n",
        "!unzip -qq images_background.zip\n",
        "!unzip -qq images_evaluation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqGfSUHZ5pB2",
        "outputId": "8fbeb101-d43f-453b-f189-e4547454b81a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-19 22:25:28--  https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip [following]\n",
            "--2023-09-19 22:25:28--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6462886 (6.2M) [application/zip]\n",
            "Saving to: ‘images_evaluation.zip.1’\n",
            "\n",
            "images_evaluation.z 100%[===================>]   6.16M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-19 22:25:29 (49.2 MB/s) - ‘images_evaluation.zip.1’ saved [6462886/6462886]\n",
            "\n",
            "--2023-09-19 22:25:29--  https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip [following]\n",
            "--2023-09-19 22:25:29--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9464212 (9.0M) [application/zip]\n",
            "Saving to: ‘images_background.zip.1’\n",
            "\n",
            "images_background.z 100%[===================>]   9.03M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-09-19 22:25:30 (157 MB/s) - ‘images_background.zip.1’ saved [9464212/9464212]\n",
            "\n",
            "replace images_background/Alphabet_of_the_Magi/character01/0709_01.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "replace images_evaluation/Angelic/character01/0965_01.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lee_alfabetos(ruta_al_directorio_del_alfabeto, nombre_del_alfabeto):\n",
        "    \"\"\"\n",
        "    Lee y devuelve todos los caracteres de un alfabeto específico que se encuentra en un directorio dado.\n",
        "\n",
        "    Parámetros:\n",
        "    - ruta_al_directorio_del_alfabeto (str): Ruta al directorio que contiene los caracteres del alfabeto.\n",
        "    - nombre_del_alfabeto (str): Nombre del alfabeto a procesar.\n",
        "\n",
        "    Retorno:\n",
        "    - np.array(datax): Una lista de imágenes de los caracteres leídos.\n",
        "    - np.array(datay): Una lista de etiquetas correspondientes a cada imagen.\n",
        "    \"\"\"\n",
        "\n",
        "    # Listas para almacenar imágenes y sus correspondientes etiquetas\n",
        "    datax = []\n",
        "    datay = []\n",
        "\n",
        "    # Listar todos los caracteres dentro del directorio del alfabeto.\n",
        "    caracteres = os.listdir(ruta_al_directorio_del_alfabeto)\n",
        "\n",
        "    for caracter in caracteres:\n",
        "        # Listar todas las imágenes asociadas a un caracter específico.\n",
        "        imagenes = os.listdir(ruta_al_directorio_del_alfabeto + caracter + '/')\n",
        "\n",
        "        for im in imagenes:\n",
        "            # Leer cada imagen en escala de grises.\n",
        "            image = cv2.imread(ruta_al_directorio_del_alfabeto + caracter + '/' + im, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Añadir la imagen leída y su etiqueta correspondiente a las listas.\n",
        "            datax.append(image)\n",
        "            datay.append(nombre_del_alfabeto + '_' + caracter)\n",
        "\n",
        "    # Convertir listas a arrays de numpy y devolver\n",
        "    return np.array(datax), np.array(datay)\n",
        "\n",
        "def preproces_omniglot(directorio_principal):\n",
        "    \"\"\"\n",
        "    Preprocesa y devuelve todas las imágenes y etiquetas de los alfabetos contenidos en el directorio principal.\n",
        "\n",
        "    Parámetros:\n",
        "    - directorio_principal (str): Ruta al directorio principal que contiene todos los alfabetos.\n",
        "\n",
        "    Retorno:\n",
        "    - datax: Todas las imágenes de los caracteres de todos los alfabetos.\n",
        "    - datay: Las etiquetas correspondientes a cada imagen.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializar variables donde se almacenarán las imágenes y etiquetas\n",
        "    datax = None\n",
        "    datay = None\n",
        "\n",
        "    # Crear un pool de procesos para paralelizar la lectura de los alfabetos.\n",
        "    # Esto aprovecha todos los núcleos del CPU para leer múltiples alfabetos simultáneamente.\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "    # Leer todos los alfabetos del directorio principal de forma paralela.\n",
        "    # Para cada subdirectorio (alfabeto) en el directorio principal, aplica la función lee_alfabetos\n",
        "    resultados = [pool.apply(lee_alfabetos,\n",
        "                             args=(\n",
        "                                 directorio_principal + '/' + directorio + '/', directorio,\n",
        "                             )) for directorio in os.listdir(directorio_principal)]\n",
        "\n",
        "    # Cerrar el pool de procesos una vez que todos han terminado.\n",
        "    pool.close()\n",
        "\n",
        "    # Procesar y combinar los resultados para crear una lista única de imágenes y etiquetas\n",
        "    for resultado in resultados:\n",
        "        if datax is None:\n",
        "            datax = resultado[0]\n",
        "            datay = resultado[1]\n",
        "        else:\n",
        "            # Añadir las imágenes y etiquetas de cada alfabeto a las listas generales.\n",
        "            datax = np.vstack([datax, resultado[0]])\n",
        "            datay = np.concatenate([datay, resultado[1]])\n",
        "\n",
        "    return datax, datay\n",
        "\n"
      ],
      "metadata": {
        "id": "Vgc2OrFV5o-G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Procesa las imágenes y etiquetas del directorio \"images_background\" y las asigna a las variables trainx y trainy.\n",
        "trainx, trainy = preproces_omniglot('images_background')\n",
        "\n",
        "# Procesa las imágenes y etiquetas del directorio \"images_evaluation\" y las asigna a las variables testx y testy.\n",
        "testx, testy = preproces_omniglot('images_evaluation')\n",
        "\n",
        "# Toma las primeras 3000 imágenes y etiquetas del conjunto de test para usarlas como conjunto de validación.\n",
        "valx = testx[0:3000]\n",
        "valy = testy[0:3000]\n",
        "\n",
        "# Actualiza el conjunto de test eliminando las primeras 3000 imágenes y etiquetas que ya están en el conjunto de validación.\n",
        "testx = testx[3000:,:,:]\n",
        "testy= testy[3000:]\n",
        "\n",
        "\n",
        "# Reinicializa trainy y asigna etiquetas numéricas para las imágenes.\n",
        "# Cada grupo de 20 imágenes recibirá el mismo número, del 0 al 963.\n",
        "trainy = []\n",
        "for i in range(964):\n",
        "    trainy.extend([i] * 20)\n",
        "\n",
        "# Reinicializa valy y asigna etiquetas numéricas para las imágenes de validación.\n",
        "# Cada grupo de 20 imágenes recibirá el mismo número, del 0 al 149.\n",
        "valy = []\n",
        "for i in range(150):\n",
        "    valy.extend([i] * 20)\n",
        "\n",
        "# Reinicializa testy y asigna etiquetas numéricas para las imágenes de test.\n",
        "# Cada grupo de 20 imágenes recibirá el mismo número, del 0 al 508.\n",
        "testy = []\n",
        "for i in range(509):\n",
        "    testy.extend([i] * 20)\n"
      ],
      "metadata": {
        "id": "oJahI4wc5o74"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imprime las formas de los arrays para conocer sus dimensiones.\n",
        "# Esto es útil para verificar que los datos se hayan dividido correctamente.\n",
        "trainx.shape, len(trainy), valx.shape, len(valy), testx.shape, len(testy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6udpb4xjjRFt",
        "outputId": "9b7c1d2e-618d-41b4-960e-e619d0e85853"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19280, 105, 105), 19280, (3000, 105, 105), 3000, (10180, 105, 105), 10180)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(shape, dtype=None):\n",
        "    \"\"\"\n",
        "    Inicializa los pesos de una capa CNN siguiendo las recomendaciones del paper:\n",
        "    http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    Los pesos se inicializan con una media de 0.0 y una desviación estándar de 0.01.\n",
        "\n",
        "    Parámetros:\n",
        "    - shape (tuple): Forma del tensor de pesos a inicializar.\n",
        "    - dtype (opcional): Tipo de datos para los valores inicializados.\n",
        "\n",
        "    Retorno:\n",
        "    - np.array: Tensor de pesos inicializado.\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
        "\n",
        "def initialize_bias(shape, dtype=None):\n",
        "    \"\"\"\n",
        "    Inicializa el sesgo (bias) de una capa CNN siguiendo las recomendaciones del paper:\n",
        "    http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "    El sesgo se inicializa con una media de 0.5 y una desviación estándar de 0.01.\n",
        "\n",
        "    Parámetros:\n",
        "    - shape (tuple): Forma del tensor de sesgo a inicializar.\n",
        "    - dtype (opcional): Tipo de datos para los valores inicializados.\n",
        "\n",
        "    Retorno:\n",
        "    - np.array: Tensor de sesgo inicializado.\n",
        "    \"\"\"\n",
        "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n"
      ],
      "metadata": {
        "id": "LHkl33p95ox2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_siamese_model(input_shape):\n",
        "    \"\"\"\n",
        "    Construye y devuelve un modelo siamés basado en la arquitectura proporcionada en:\n",
        "    http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
        "\n",
        "    Parámetros:\n",
        "    - input_shape (tuple): Forma del tensor de entrada para cada una de las dos imágenes.\n",
        "\n",
        "    Retorno:\n",
        "    - siamese_net (Model): Modelo siamés para comparar la similitud entre dos imágenes.\n",
        "    \"\"\"\n",
        "\n",
        "    # Definir los tensores para las dos imágenes de entrada.\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "\n",
        "    # Construcción de la Red Neuronal Convolucional.\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
        "                     kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (7,7), activation='relu',\n",
        "                     kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(128, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(MaxPooling2D())\n",
        "    model.add(Conv2D(256, (4,4), activation='relu', kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='sigmoid',\n",
        "                    kernel_regularizer=l2(1e-3),\n",
        "                    kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
        "\n",
        "    # Generar las codificaciones (vectores de características) para las dos imágenes.\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "\n",
        "    # Añadir una capa personalizada para calcular la diferencia absoluta entre las codificaciones.\n",
        "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "\n",
        "    # Añadir una capa densa con una unidad sigmoidal para generar la puntuación de similitud.\n",
        "    prediction = Dense(1, activation='sigmoid', bias_initializer=initialize_bias)(L1_distance)\n",
        "\n",
        "    # Conectar las entradas con las salidas.\n",
        "    siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
        "\n",
        "    # Devolver el modelo siamés.\n",
        "    return siamese_net\n"
      ],
      "metadata": {
        "id": "S0NA5nWw5ot9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construir el modelo siamés con una forma de entrada de (105, 105, 1), lo que indica\n",
        "# que las imágenes de entrada serán de 105x105 píxeles con un solo canal (escala de grises).\n",
        "model = get_siamese_model((105, 105, 1))\n",
        "\n",
        "# Mostrar un resumen del modelo, incluyendo la arquitectura, número de parámetros, etc.\n",
        "model.summary()\n",
        "\n",
        "# Definir el optimizador Adam con una tasa de aprendizaje de 0.00006.\n",
        "optimizer = Adam(learning_rate = 0.00006)\n",
        "\n",
        "# Compilar el modelo siamés.\n",
        "# Se utilizará la \"binary_crossentropy\" como función de pérdida ya que la tarea es de clasificación binaria\n",
        "# (dos imágenes son similares o no).\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "SPFm49he5or8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d42b67-f763-4dea-9498-c29b38ec9703"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 105, 105, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 105, 105, 1)]        0         []                            \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)   (None, 4096)                 3894764   ['input_3[0][0]',             \n",
            "                                                          8          'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 4096)                 0         ['sequential_1[0][0]',        \n",
            "                                                                     'sequential_1[1][0]']        \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1)                    4097      ['lambda_1[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38951745 (148.59 MB)\n",
            "Trainable params: 38951745 (148.59 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_lote(tamaño_lote, s=\"val\"):\n",
        "    \"\"\"\n",
        "    Crea un lote de pares de imágenes con clases mixtas.\n",
        "\n",
        "    Parámetros:\n",
        "    - tamaño_lote (int): Número de pares de imágenes en el lote.\n",
        "    - s (str): Indica el conjunto de datos a utilizar (\"train\" o \"val\").\n",
        "\n",
        "    Retorno:\n",
        "    - pares (list): Lista con dos arrays, cada uno contiene imágenes del lote.\n",
        "    - etiquetas (np.array): Vector de etiquetas binarias indicando si las imágenes del par pertenecen a la misma clase.\n",
        "    \"\"\"\n",
        "\n",
        "    # Seleccionar el conjunto de datos adecuado basado en el argumento 's'.\n",
        "    if s == \"train\":\n",
        "        X = trainx\n",
        "        categorias = trainy\n",
        "    elif s == \"val\":\n",
        "        X = valx\n",
        "        categorias = valy\n",
        "    else:\n",
        "        print(\"Error, valor del segundo argumento no valido\")\n",
        "        return\n",
        "\n",
        "    n_imagenes, w, h = X.shape\n",
        "\n",
        "    # Inicializar 2 arrays vacíos para el lote de imágenes de entrada.\n",
        "    pares = [np.zeros((tamaño_lote, h, w, 1)) for i in range(2)]\n",
        "\n",
        "    # Inicializar vector para las etiquetas.\n",
        "    etiquetas = np.zeros((tamaño_lote,))\n",
        "\n",
        "    for i in range(tamaño_lote):\n",
        "        # Elegir una categoría aleatoria.\n",
        "        categoria = rng.choice(categorias[-1]+1)\n",
        "\n",
        "        # Elegir dos índices aleatorios dentro de esa categoría.\n",
        "        idx_1 = rng.randint(0, 20)\n",
        "        idx_2 = rng.randint(0, 20)\n",
        "\n",
        "        if rng.rand() < 0.5:\n",
        "            # La mitad del tiempo, elige una categoría diferente para la segunda imagen.\n",
        "            categoria_2 = random.choice([num for num in range(categorias[-1] + 1) if num != categoria])\n",
        "            etiquetas[i] = 0\n",
        "        else:\n",
        "            # La otra mitad del tiempo, mantiene la misma categoría para la segunda imagen.\n",
        "            categoria_2 = categoria\n",
        "            etiquetas[i] = 1\n",
        "\n",
        "        # Asignar las imágenes seleccionadas a los arrays de pares.\n",
        "        pares[0][i,:,:,:] = X[categoria * 20 + idx_1].reshape(w, h, 1)\n",
        "        pares[1][i,:,:,:] = X[categoria_2 * 20 + idx_2].reshape(w, h, 1)\n",
        "\n",
        "    return pares, etiquetas\n"
      ],
      "metadata": {
        "id": "DLkVqC3a5ooA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tarea_fewShot(N, k=1):\n",
        "    \"\"\"\n",
        "    Crea pares de una imagen de prueba y un conjunto de soporte para probar el aprendizaje one-shot\n",
        "    de N vías con k muestras.\n",
        "\n",
        "    Parámetros:\n",
        "    - N (int): Número de clases distintas en la tarea.\n",
        "    - k (int): Número de muestras por clase en la tarea.\n",
        "\n",
        "    Retorno:\n",
        "    - pares (list): Lista con dos arrays, el primero contiene imágenes de prueba y el segundo contiene el conjunto de soporte.\n",
        "    - etiquetas (np.array): Etiquetas binarias que indican si la imagen de prueba y la imagen de soporte son de la misma clase.\n",
        "    - indices_verdaderos (np.array): Índices de las ubicaciones donde se colocaron las imágenes de la categoría correcta.\n",
        "    \"\"\"\n",
        "\n",
        "    # Seleccionar el conjunto de datos de prueba.\n",
        "    X = testx\n",
        "    categorias = testy\n",
        "\n",
        "    # Obtener las dimensiones de las imágenes.\n",
        "    n_imagenes, w, h = X.shape\n",
        "\n",
        "    # Elegir k muestras aleatoriamente para cada una de las N categorías.\n",
        "    indices = rng.choice(20, size=(N, k), replace=True)\n",
        "\n",
        "    # Elegir N categorías aleatoriamente sin repetición.\n",
        "    categorias = rng.choice(categorias[-1] + 1, size=(N,), replace=False)\n",
        "\n",
        "    # Elegir la categoría verdadera y una imagen aleatoria de esa categoría.\n",
        "    categoria_verdadera = categorias[0]\n",
        "    ex1 = rng.choice(20, replace=False)\n",
        "    imagen_test = np.asarray([X[categoria_verdadera*20 + ex1, :, :]]*N*k).reshape(N*k, w, h, 1)\n",
        "\n",
        "    # Crear el conjunto de soporte con las imágenes elegidas.\n",
        "    soporte = np.zeros((N*k, w, h, 1))\n",
        "    for i, categoria in enumerate(categorias):\n",
        "        soporte[i*k: i*k + k] = X[categoria*20 + indices[i]].reshape(k, w, h, 1)\n",
        "\n",
        "    # Inicializar las etiquetas, siendo 1 para las imágenes de la categoría verdadera y 0 para las demás.\n",
        "    etiquetas = np.zeros((N*k,))\n",
        "    etiquetas[:k] = 1\n",
        "\n",
        "    # Barajar los índices y utilizarlos para mezclar los otros arrays.\n",
        "    shuffled_indices = np.arange(N*k)\n",
        "    np.random.shuffle(shuffled_indices)\n",
        "\n",
        "    etiquetas = etiquetas[shuffled_indices]\n",
        "    imagen_test = imagen_test[shuffled_indices]\n",
        "    soporte = soporte[shuffled_indices]\n",
        "\n",
        "    # Los índices verdaderos son las ubicaciones donde colocamos las imágenes de la categoría correcta (es decir, las que tienen target=1).\n",
        "    indices_verdaderos = np.where(etiquetas == 1)[0]\n",
        "\n",
        "    pares = [imagen_test, soporte]\n",
        "\n",
        "    return pares, etiquetas, indices_verdaderos\n"
      ],
      "metadata": {
        "id": "PMokZzDs5ol4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir tamaño del lote, número de iteraciones y número de épocas\n",
        "tamaño_lote = 32\n",
        "n_iter = 2000\n",
        "n_epocas = 25\n",
        "\n",
        "# Decorador para compilar una función de TensorFlow y mejorar su ejecución\n",
        "@tf.function\n",
        "def train_step(inputs, etiquetas):\n",
        "    \"\"\"Realizar un paso de entrenamiento.\n",
        "\n",
        "    Parámetros:\n",
        "    - inputs (list): Imágenes de entrada.\n",
        "    - etiquetas (np.array): Etiquetas verdaderas.\n",
        "\n",
        "    Retorno:\n",
        "    - loss (Tensor): Valor de la pérdida calculada.\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Pase hacia adelante\n",
        "        predicciones = model(inputs, training=True)\n",
        "        # Calcular el valor de la pérdida\n",
        "        loss = loss_fn(etiquetas, predicciones)\n",
        "\n",
        "    # Calcular los gradientes\n",
        "    gradientes = tape.gradient(loss, model.trainable_variables)\n",
        "    # Actualizar los pesos del modelo\n",
        "    optimizer.apply_gradients(zip(gradientes, model.trainable_variables))\n",
        "    # Actualizar las métricas\n",
        "    train_acc_metric.update_state(etiquetas, predicciones)\n",
        "    # Retornar el valor de la pérdida\n",
        "    return loss\n",
        "\n",
        "# Definir la función de pérdida\n",
        "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Definir la métrica de precisión\n",
        "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "# Bucle de entrenamiento por época\n",
        "for epoca in range(n_epocas):\n",
        "    print(\"\\nInicio de la época %d\" % (epoca,))\n",
        "\n",
        "    loss_total = 0\n",
        "    for step in tnrange(n_iter):\n",
        "        # Crear un lote de datos de entrenamiento\n",
        "        inputs, etiquetas = crea_lote(tamaño_lote, s='train')\n",
        "        valor_loss = train_step(inputs, etiquetas)\n",
        "        loss_total += valor_loss\n",
        "\n",
        "        # Verificar cada 500 episodios\n",
        "        if (step + 1) % 500 == 0:\n",
        "            # Obtener la precisión actual de entrenamiento\n",
        "            acc_actual = float(train_acc_metric.result())\n",
        "\n",
        "            # Almacenar la pérdida promedio de los últimos 500 episodios\n",
        "            loss_media_500 = loss_total / (step + 1)\n",
        "\n",
        "            # Calcular la precisión de validación\n",
        "            val_inputs, val_etiquetas = crea_lote(300, s=\"val\")\n",
        "            val_predic = model(val_inputs, training=False)\n",
        "            val_predic_sd = np.squeeze((val_predic > 0.5).numpy().astype(\"int32\"))\n",
        "            val_acc = np.mean(val_predic_sd == val_etiquetas)\n",
        "\n",
        "            # Imprimir valores (para depuración)\n",
        "            print(\"Después del episodio %d: Precisión de entrenamiento: %.4f, precisión de validación: %.4f, Pérdida promedio: %.4f\"\n",
        "                  % ((step + 1), acc_actual, val_acc, loss_media_500))\n",
        "\n",
        "    # Al final de la época, calcular e imprimir las estadísticas globales de la época\n",
        "    loss_media_epoca = loss_total / n_iter\n",
        "    acc_entrenamiento_epoca = float(train_acc_metric.result())\n",
        "\n",
        "    print(\n",
        "        \"Pérdida de entrenamiento para la época %d: %.4f - Precisión: %.4f\"\n",
        "        % (epoca, loss_media_epoca, acc_entrenamiento_epoca)\n",
        "    )\n",
        "\n",
        "    # Resetear la pérdida total y la métrica de precisión al FINAL de la época\n",
        "    loss_total = 0\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Actualizar la tasa de aprendizaje, reduciéndola en un 1%\n",
        "    lr_actual = optimizer.learning_rate.numpy()\n",
        "    nuevo_lr = lr_actual * 0.99\n",
        "    optimizer.learning_rate.assign(nuevo_lr)\n",
        "\n"
      ],
      "metadata": {
        "id": "xm6tpr4L5oiP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de las variables de prueba y configuración de la evaluación\n",
        "n_test = 1000  # Número de pruebas a realizar\n",
        "N_way = 5      # Número de categorías distintas en cada prueba (N-way one-shot learning)\n",
        "s_shot = 1    # Número de imágenes por categoría que se proporcionará (1 para one-shot, 5 para five-shot, etc.)\n",
        "\n",
        "# Descomentar las siguientes líneas si se desea cargar un modelo pre-entrenado\n",
        "# from tensorflow.keras.models import load_model\n",
        "# nombre_modelo = f'Omniglot_siamesa2Overfit.h5'\n",
        "# model = load_model(nombre_modelo)  # Carga el modelo con el nombre definido\n",
        "\n",
        "# Inicialización de la variable para contar las pruebas correctas\n",
        "n_correct = 0\n",
        "\n",
        "print(\"Evaluating model on {} random {} way {}-shot learning tasks ...\".format(n_test, N_way, s_shot))\n",
        "\n",
        "# Realizar pruebas N_way one-shot learning\n",
        "for i in tnrange(n_test):\n",
        "    # Obtener un conjunto de prueba y conjunto de soporte con sus etiquetas\n",
        "    inputs, etiquetas, indices_verdaderos = tarea_fewShot(N_way, s_shot)\n",
        "\n",
        "    # Predecir las probabilidades de similitud entre la imagen de prueba y las imágenes del conjunto de soporte\n",
        "    probs = model(inputs)\n",
        "\n",
        "    # Comprobar si la predicción del modelo es correcta comparando el índice de la probabilidad máxima con los índices verdaderos\n",
        "    if np.argmax(probs) in indices_verdaderos:\n",
        "        n_correct += 1\n",
        "\n",
        "# Calcular y mostrar la precisión promedio del modelo en las tareas N_way one-shot learning\n",
        "test_acc = (n_correct / n_test) * 100\n",
        "print(\"Got an average of {}% accuracy for {} way {}-shot learning\".format(test_acc, N_way, s_shot))\n"
      ],
      "metadata": {
        "id": "lyTNGv3M5ogA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TCNcU4l5oeQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}