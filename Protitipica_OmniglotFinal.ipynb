{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HG2a9spjYI7U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import cv2\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tnrange\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para facilitar la ejecución del codigo se descargan directamente los datos y se descomprimen los archivos.\n",
        "\n",
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\n",
        "!wget https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip\n",
        "\n",
        "!unzip -qq images_background.zip\n",
        "!unzip -qq images_evaluation.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cU0EFSUYLqb",
        "outputId": "6b3ea4c8-14b5-4fe6-acd6-858201a94ce4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-19 22:33:47--  https://github.com/brendenlake/omniglot/raw/master/python/images_evaluation.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip [following]\n",
            "--2023-09-19 22:33:47--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6462886 (6.2M) [application/zip]\n",
            "Saving to: ‘images_evaluation.zip’\n",
            "\n",
            "images_evaluation.z 100%[===================>]   6.16M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-09-19 22:33:48 (70.5 MB/s) - ‘images_evaluation.zip’ saved [6462886/6462886]\n",
            "\n",
            "--2023-09-19 22:33:48--  https://github.com/brendenlake/omniglot/raw/master/python/images_background.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip [following]\n",
            "--2023-09-19 22:33:48--  https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9464212 (9.0M) [application/zip]\n",
            "Saving to: ‘images_background.zip’\n",
            "\n",
            "images_background.z 100%[===================>]   9.03M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-09-19 22:33:49 (84.3 MB/s) - ‘images_background.zip’ saved [9464212/9464212]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lee_alfabetos(ruta_al_directorio_del_alfabeto, nombre_del_alfabeto):\n",
        "    \"\"\"\n",
        "    Lee todos los caracteres de los alfabetos que contenga el directorio dado.\n",
        "\n",
        "    Argumentos:\n",
        "    - ruta_al_directorio_del_alfabeto: Ruta del directorio que contiene el alfabeto.\n",
        "    - nombre_del_alfabeto: Nombre del alfabeto.\n",
        "\n",
        "    Devuelve:\n",
        "    - datax: Lista de imágenes.\n",
        "    - datay: Lista de etiquetas asociadas a las imágenes.\n",
        "    \"\"\"\n",
        "    datax = []\n",
        "    datay = []\n",
        "\n",
        "    # Listar todos los caracteres en el directorio del alfabeto\n",
        "    caracteres = os.listdir(ruta_al_directorio_del_alfabeto)\n",
        "\n",
        "    for caracter in caracteres:\n",
        "        # Listar todas las imágenes dentro del directorio del caracter\n",
        "        imagenes = os.listdir(ruta_al_directorio_del_alfabeto + caracter + '/')\n",
        "        for im in imagenes:\n",
        "            # Leer y redimensionar la imagen en escala de grises\n",
        "            imagen = cv2.resize(\n",
        "                cv2.imread(ruta_al_directorio_del_alfabeto + caracter + '/' + im, cv2.IMREAD_GRAYSCALE),\n",
        "                (28, 28)\n",
        "            )\n",
        "\n",
        "            # Crear rotaciones de la imagen (90, 180 y 270 grados)\n",
        "            rotada_90 = ndimage.rotate(imagen, 90)\n",
        "            rotada_180 = ndimage.rotate(imagen, 180)\n",
        "            rotada_270 = ndimage.rotate(imagen, 270)\n",
        "\n",
        "            # Agregar las imágenes y sus rotaciones al conjunto de datos\n",
        "            datax.extend((imagen, rotada_90, rotada_180, rotada_270))\n",
        "\n",
        "            # Agregar etiquetas para las imágenes y sus rotaciones\n",
        "            datay.extend((\n",
        "                ruta_al_directorio_del_alfabeto + '_' + caracter + '_0',\n",
        "                ruta_al_directorio_del_alfabeto + '_' + caracter + '_90',\n",
        "                ruta_al_directorio_del_alfabeto + '_' + caracter + '_180',\n",
        "                ruta_al_directorio_del_alfabeto + '_' + caracter + '_270'\n",
        "            ))\n",
        "\n",
        "    return np.array(datax), np.array(datay)\n",
        "\n",
        "def preproces_omniglot(directorio_principal):\n",
        "    \"\"\"\n",
        "    Llama a la función lee_alfabetos para leer cada uno de los alfabetos del directorio principal.\n",
        "\n",
        "    Argumentos:\n",
        "    - directorio_principal: Ruta del directorio que contiene varios alfabetos.\n",
        "\n",
        "    Devuelve:\n",
        "    - datax: Lista consolidada de todas las imágenes.\n",
        "    - datay: Lista consolidada de todas las etiquetas.\n",
        "    \"\"\"\n",
        "    datax = None\n",
        "    datay = None\n",
        "\n",
        "    # Utilizar múltiples núcleos del procesador para procesar los alfabetos en paralelo\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "    # Leer cada directorio (alfabeto) en el directorio principal\n",
        "    results = [pool.apply(lee_alfabetos,\n",
        "                          args=(\n",
        "                              directorio_principal + '/' + directorio + '/', directorio,\n",
        "                          )) for directorio in os.listdir(directorio_principal)]\n",
        "    pool.close()\n",
        "\n",
        "    # Consolidar los datos de todos los alfabetos\n",
        "    for resul in results:\n",
        "        if datax is None:\n",
        "            datax = resul[0]\n",
        "            datay = resul[1]\n",
        "        else:\n",
        "            datax = np.vstack([datax, resul[0]])\n",
        "            datay = np.concatenate([datay, resul[1]])\n",
        "\n",
        "    return datax, datay\n"
      ],
      "metadata": {
        "id": "PS_LeMU_YLmZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Llama a la función preproces_omniglot para preprocesar las imágenes en el directorio 'images_background' y\n",
        "# almacena las imágenes y sus etiquetas en trainx y trainy, respectivamente.\n",
        "trainx, trainy = preproces_omniglot('images_background')\n",
        "\n",
        "# Llama a la función preproces_omniglot para preprocesar las imágenes en el directorio 'images_evaluation' y\n",
        "# almacena las imágenes y sus etiquetas en testx y testy, respectivamente.\n",
        "testx, testy = preproces_omniglot('images_evaluation')\n",
        "\n",
        "# Devuelve las dimensiones (shapes) de los conjuntos de datos trainx, trainy, testx y testy.\n",
        "# Esto es útil para entender rápidamente el número de ejemplos y las dimensiones de las imágenes en cada conjunto.\n",
        "trainx.shape, trainy.shape, testx.shape, testy.shape\n"
      ],
      "metadata": {
        "id": "whZR2s9WYLkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21d022f-bd1e-4fb6-afb2-f0fefc7b0046"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((77120, 28, 28), (77120,), (52720, 28, 28), (52720,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_muestra(n_way, n_support, n_query, datax, datay):\n",
        "    \"\"\"\n",
        "    Crea una muestra aleatoria de tamaño n_support+n_query, de imágenes de n_way clases.\n",
        "\n",
        "    Entrada:\n",
        "        n_way (int): Número de clases.\n",
        "        n_support (int): Número de imágenes en el conjunto soporte por clase.\n",
        "        n_query (int): Número de imágenes para clasificar por clase.\n",
        "        datax (np.array): Conjunto de imágenes.\n",
        "        datay (np.array): Conjunto de etiquetas.\n",
        "\n",
        "    Salida:\n",
        "        (dict) de:\n",
        "            (tf.Tensor): Muestra de imágenes de tamaño (n_way, n_support+n_query, (dim)).\n",
        "            (int): n_way.\n",
        "            (int): n_support.\n",
        "            (int): n_query.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtiene las clases únicas en el conjunto de etiquetas\n",
        "    clases_unicas = np.unique(datay)\n",
        "\n",
        "    # Elige n_way clases de manera aleatoria sin repetición\n",
        "    clases_elegidas = np.random.choice(clases_unicas, n_way, replace=False)\n",
        "\n",
        "    # Total de ejemplos por clase\n",
        "    ejemplos_por_clase = n_support + n_query\n",
        "    # Crea una lista de índices para todo el conjunto de etiquetas\n",
        "    indices = np.arange(len(datay))\n",
        "\n",
        "    muestra = []\n",
        "\n",
        "    for clase in clases_elegidas:\n",
        "        # Encuentra los índices de las imágenes que pertenecen a la clase actual\n",
        "        clase_indices = indices[datay == clase]\n",
        "\n",
        "        # Elige aleatoriamente ejemplos_por_clase índices de la clase actual\n",
        "        indices_elegidos = np.random.choice(clase_indices, ejemplos_por_clase, replace=False)\n",
        "\n",
        "        # Agrega las imágenes elegidas a la muestra\n",
        "        muestra.append(datax[indices_elegidos])\n",
        "\n",
        "    # Convierte la lista de imágenes en un tensor de TensorFlow\n",
        "    muestra = tf.convert_to_tensor(np.array(muestra), dtype=tf.float32)\n",
        "\n",
        "    # Devuelve un diccionario con la muestra y otros metadatos\n",
        "    return {\n",
        "        'imagenes': muestra,\n",
        "        'n_way': n_way,\n",
        "        'n_support': n_support,\n",
        "        'n_query': n_query\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Kb3FGoXJYLex"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def red_convolucional(tamaño_entrada, dimension_caracteristicas):\n",
        "    \"\"\"\n",
        "    Define y retorna una red convolucional que se usará para extraer características de las imágenes.\n",
        "\n",
        "    Entrada:\n",
        "        tamaño_entrada (tuple): Dimensiones de la imagen de entrada (alto, ancho, canales).\n",
        "        dimension_caracteristicas (int): Número de características a extraer con la última capa densa.\n",
        "\n",
        "    Salida:\n",
        "        model (tf.keras.Sequential): Modelo de red convolucional.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializa un modelo secuencial en Keras.\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Primera capa convolucional.\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=tamaño_entrada))  # Convolucional con 64 filtros y kernel de 3x3.\n",
        "    model.add(layers.BatchNormalization())  # Normalización por lotes para estabilizar y acelerar el entrenamiento.\n",
        "    model.add(layers.ReLU())  # Función de activación ReLU.\n",
        "    model.add(layers.MaxPooling2D((2, 2)))  # Reducción de dimensiones mediante MaxPooling.\n",
        "\n",
        "    # Añade tres bloques idénticos de capas convolucionales, cada bloque consiste en una capa convolucional,\n",
        "    # una capa de normalización por lotes, una activación ReLU y una capa de MaxPooling.\n",
        "    for _ in range(3):\n",
        "        model.add(layers.Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.ReLU())\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Añade una capa que aplana la salida anterior para prepararla para la capa densa.\n",
        "    model.add(layers.Flatten())\n",
        "    # Añade una capa densa que genera un vector de características con una longitud igual a dimension_caracteristicas.\n",
        "    model.add(layers.Dense(dimension_caracteristicas))\n",
        "\n",
        "    return model  # Retorna el modelo construido.\n"
      ],
      "metadata": {
        "id": "NKbJgRLYYLcw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_dist(x, y):\n",
        "    \"\"\"\n",
        "    Calcula la distancia euclidea al cuadrado entre x e y.\n",
        "\n",
        "    Entrada:\n",
        "        x (tf.Tensor): tamaño (n, d). n es n_way*n_query.\n",
        "        y (tf.Tensor): tamaño (m, d). m es n_way.\n",
        "\n",
        "    Salida:\n",
        "        tf.Tensor: tamaño (n, m). Para cada imagen de consulta, las distancias a cada uno de los prototipos.\n",
        "    \"\"\"\n",
        "    # Obtiene las dimensiones de x e y.\n",
        "    n = tf.shape(x)[0]  # Número de filas en x.\n",
        "    m = tf.shape(y)[0]  # Número de filas en y.\n",
        "    d = tf.shape(x)[1]  # Número de columnas (características) en x (o y, ya que ambos tienen la misma dimensión en columnas).\n",
        "\n",
        "    # Expande las dimensiones de x e y para hacerlos broadcastable.\n",
        "    # x pasa de (n, d) a (n, 1, d).\n",
        "    x = tf.expand_dims(x, 1)\n",
        "    # Repite x 'm' veces en la segunda dimensión para que tenga tamaño (n, m, d).\n",
        "    x = tf.tile(x, (1, m, 1))\n",
        "\n",
        "    # y pasa de (m, d) a (1, m, d).\n",
        "    y = tf.expand_dims(y, 0)\n",
        "    # Repite y 'n' veces en la primera dimensión para que tenga tamaño (n, m, d).\n",
        "    y = tf.tile(y, (n, 1, 1))\n",
        "\n",
        "    # Calcula la diferencia al cuadrado entre x e y, y la suma a lo largo del eje de las características (axis=2).\n",
        "    # El resultado es una matriz de tamaño (n, m) donde cada entrada (i, j) representa la distancia euclidiana al cuadrado\n",
        "    # entre el i-ésimo vector en x y el j-ésimo vector en y.\n",
        "    return tf.reduce_sum(tf.square(x - y), axis=2)\n"
      ],
      "metadata": {
        "id": "GPYy4xs-YLbF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def floss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula la función de pérdida personalizada para dos vectores: uno que contiene las etiquetas verdaderas y\n",
        "    otro que contiene las probabilidades predichas de las clases.\n",
        "\n",
        "    Entrada:\n",
        "        y_true (tf.Tensor): Tensor que contiene las etiquetas verdaderas en formato one-hot encoding.\n",
        "        y_pred (tf.Tensor): Tensor que contiene las probabilidades predichas de las clases.\n",
        "\n",
        "    Salida:\n",
        "        tf.Tensor: Un valor escalar que representa la pérdida calculada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Multiplica elemento a elemento las etiquetas verdaderas con las probabilidades predichas\n",
        "    # Luego, sumamos esos valores a lo largo del último eje (axis=-1)\n",
        "    # Finalmente, calculamos el negativo de la media de esos valores sumados\n",
        "\n",
        "    loss_val = -tf.reduce_mean(tf.reduce_sum(y_true * y_pred, axis=-1))\n",
        "\n",
        "    return loss_val"
      ],
      "metadata": {
        "id": "34v6aSWuYLZH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracyProt(y_true, y_pred, n_way, n_query):\n",
        "    \"\"\"\n",
        "    Calcula la precisión de las predicciones basándose en etiquetas verdaderas y predicciones.\n",
        "\n",
        "    Entrada:\n",
        "        y_true (tf.Tensor): Tensor que contiene las etiquetas verdaderas en formato one-hot encoding.\n",
        "        y_pred (tf.Tensor): Tensor que contiene las probabilidades predichas de las clases.\n",
        "        n_way (int): Número de clases únicas.\n",
        "        n_query (int): Número de imágenes para clasificar por clase.\n",
        "\n",
        "    Salida:\n",
        "        float: Precisión de las predicciones.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encuentra el índice del valor máximo en y_pred a lo largo del eje 1\n",
        "    # Esto nos dará la clase predicha para cada muestra.\n",
        "    predicciones = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Encuentra el índice del valor máximo en y_true a lo largo del eje 1\n",
        "    # Esto nos dará la etiqueta verdadera para cada muestra.\n",
        "    etiquetas_correctas = tf.argmax(y_true, axis=1)\n",
        "\n",
        "    # Compara las predicciones con las etiquetas correctas y cuenta cuántas coinciden.\n",
        "    total_correct = tf.reduce_sum(tf.cast(tf.equal(predicciones, etiquetas_correctas), tf.int32))\n",
        "\n",
        "    # Calcula la precisión dividiendo el número total de predicciones correctas\n",
        "    # por el número total de predicciones (n_way * n_query).\n",
        "    accuracyp = total_correct / (n_way * n_query)\n",
        "\n",
        "    return accuracyp"
      ],
      "metadata": {
        "id": "Wks8flsgYe5O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Proto(sample, n_way, n_support, n_query, model):\n",
        "    \"\"\"\n",
        "    Implementa el Prototipo de redes para el aprendizaje de pocas tomas.\n",
        "\n",
        "    Entrada:\n",
        "        sample (dict): Diccionario que contiene las imágenes.\n",
        "        n_way (int): Número de clases únicas.\n",
        "        n_support (int): Número de imágenes de soporte por clase.\n",
        "        n_query (int): Número de imágenes de consulta por clase.\n",
        "        model (tf.keras.Model): Modelo de red neuronal para extraer características.\n",
        "\n",
        "    Salida:\n",
        "        loss (tf.Tensor): Valor de la función de pérdida calculada.\n",
        "        target_inds_onehot (tf.Tensor): Etiquetas verdaderas en formato one-hot encoding.\n",
        "        log_p_y (tf.Tensor): Log-probabilidades predichas.\n",
        "    \"\"\"\n",
        "\n",
        "    # Separa las imágenes de soporte y consulta del diccionario 'sample'\n",
        "    x_support = sample['imagenes'][:, :n_support]\n",
        "    x_query = sample['imagenes'][:, n_support:]\n",
        "\n",
        "    # Reajusta las dimensiones de las imágenes de soporte y consulta\n",
        "    x_support = np.reshape(x_support, (x_support.shape[0] * x_support.shape[1], *x_support.shape[2:]))\n",
        "    x_query = np.reshape(x_query, (x_query.shape[0] * x_query.shape[1], *x_query.shape[2:]))\n",
        "\n",
        "    # Convierte las imágenes a tensores y normaliza sus valores (0-255 a 0-1)\n",
        "    x_support = tf.convert_to_tensor(x_support / 255.0, dtype=tf.float32)\n",
        "    x_query = tf.convert_to_tensor(x_query / 255.0, dtype=tf.float32)\n",
        "\n",
        "    # Genera las etiquetas verdaderas para las imágenes de consulta en formato one-hot\n",
        "    target_inds = [i // n_query for i in range(n_way * n_query)]\n",
        "    target_inds_onehot = tf.keras.utils.to_categorical(target_inds, num_classes=n_way)\n",
        "    target_inds_onehot = tf.convert_to_tensor(target_inds_onehot)\n",
        "\n",
        "    # Usa el modelo para extraer las características de las imágenes de soporte y consulta\n",
        "    z_support = model(x_support)\n",
        "    z_query = model(x_query)\n",
        "\n",
        "    # Calcula el prototipo (representación promedio) para cada clase a partir de las características de soporte\n",
        "    z_proto = tf.reduce_mean(tf.reshape(z_support, (n_way, n_support, -1)), axis=1)\n",
        "\n",
        "    # Calcula la distancia euclídea entre las características de consulta y los prototipos\n",
        "    dists = euclidean_dist(z_query, z_proto)\n",
        "\n",
        "    # Calcula las log-probabilidades predichas a partir de las distancias\n",
        "    log_p_y = tf.nn.log_softmax(-dists, axis=1)\n",
        "\n",
        "    # Calcula la función de pérdida usando las etiquetas verdaderas y las log-probabilidades predichas\n",
        "    loss = floss(target_inds_onehot, log_p_y)\n",
        "\n",
        "    return loss, target_inds_onehot, log_p_y\n"
      ],
      "metadata": {
        "id": "lAcWwPm-Ye28"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epocas, tamaño_epoca):\n",
        "    \"\"\"\n",
        "    Entrena el modelo de una red prototípica utilizando aprendizaje de pocos disparos.\n",
        "\n",
        "    Argumentos de entrada:\n",
        "    - model (tf.keras.Model): Modelo prototípico basado en una red convolucional.\n",
        "    - optimizer (tf.keras.optimizers.Optimizer): Optimizador utilizado para actualizar los pesos del modelo.\n",
        "    - train_x (np.array): Conjunto de imágenes de entrenamiento.\n",
        "    - train_y (np.array): Etiquetas correspondientes a las imágenes de entrenamiento.\n",
        "    - n_way (int): Número de clases distintas a considerar en cada episodio de aprendizaje.\n",
        "    - n_support (int): Número de imágenes por clase que se usan como ejemplos de soporte en cada episodio.\n",
        "    - n_query (int): Número de imágenes por clase que se usan como ejemplos de consulta en cada episodio.\n",
        "    - max_epocas (int): Número máximo de épocas de entrenamiento.\n",
        "    - tamaño_epoca (int): Número de episodios por época.\n",
        "\n",
        "    Salida:\n",
        "    - epoca_acc (float): Precisión del modelo en la última época de entrenamiento.\n",
        "    \"\"\"\n",
        "    # Programa un decaimiento exponencial para la tasa de aprendizaje del optimizador.\n",
        "    scheduler = tf.keras.optimizers.schedules.ExponentialDecay(0.001, decay_steps=2000, decay_rate=0.5, staircase=True)\n",
        "\n",
        "    epoca = 0  # Contador de épocas realizadas\n",
        "    stop = False  # Condición para detener el entrenamiento, actualmente no se utiliza\n",
        "    accuracies = []  # Lista para almacenar las precisión de cada época\n",
        "\n",
        "    # Bucle de entrenamiento principal\n",
        "    while epoca < max_epocas and not stop:\n",
        "        running_loss = 0.0  # Acumulador de la pérdida durante la época\n",
        "        running_acc = 0.0  # Acumulador de la precisión durante la época\n",
        "\n",
        "        # Bucle para cada episodio dentro de una época\n",
        "        for episode in tnrange(tamaño_epoca, desc=\"Epoca {:d} Entrenamiento\".format(epoca + 1)):\n",
        "            tf.keras.backend.clear_session()  # Borra el gráfico anterior y previene el aumento de memoria\n",
        "\n",
        "            # Permite el seguimiento automático de las operaciones para calcular gradientes más adelante\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Crea una muestra de entrenamiento para el episodio actual\n",
        "                muestra = crea_muestra(n_way, n_support, n_query, train_x, train_y)\n",
        "\n",
        "                # Calcula la pérdida usando el modelo prototípico\n",
        "                loss, target_inds_onehot, log_p_y  = Proto(muestra, n_way, n_support, n_query, model)\n",
        "\n",
        "            # Calcula los gradientes respecto a la pérdida\n",
        "            gradients = tape.gradient(loss, model.trainable_variables)\n",
        "            # Aplica los gradientes al modelo\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Calcula la precisión del episodio\n",
        "            accuracy = accuracyProt(target_inds_onehot, log_p_y, n_way, n_query)\n",
        "\n",
        "            # Actualiza los acumuladores\n",
        "            running_loss += loss\n",
        "            running_acc += accuracy\n",
        "\n",
        "        # Calcula las métricas promedio de la época\n",
        "        epoca_loss = running_loss / tamaño_epoca\n",
        "        epoca_acc = running_acc / tamaño_epoca\n",
        "\n",
        "        # Muestra las métricas de la época\n",
        "        print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoca + 1, epoca_loss, epoca_acc))\n",
        "\n",
        "        epoca += 1  # Incrementa el contador de épocas\n",
        "\n",
        "    return epoca_acc  # Devuelve la precisión de la última época\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4UGTGByvYe1N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    \"\"\"\n",
        "    Crea un modelo de red neuronal convolucional para procesar imágenes de 28x28 píxeles en escala de grises.\n",
        "\n",
        "    Devoluciones:\n",
        "        tf.keras.Model: Modelo convolucional con una salida en un espacio de características de dimensión 64.\n",
        "    \"\"\"\n",
        "    return red_convolucional((28, 28, 1), 64)\n"
      ],
      "metadata": {
        "id": "FOoINKfmYsrN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EaLi2rFYezO",
        "outputId": "9c1861c8-4963-4f76-c9e8-6c3224ca37f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 28, 28, 64)        256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 14, 14, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 7, 7, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 3, 3, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 3, 3, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 3, 3, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 1, 1, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 116608 (455.50 KB)\n",
            "Trainable params: 116096 (453.50 KB)\n",
            "Non-trainable params: 512 (2.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parámetros del modelo y del entrenamiento\n",
        "n_ways = [60]  # Lista de diferentes \"n_way\" a considerar (en este caso, solo 60 clases)\n",
        "n_support = 5  # Número de imágenes de soporte por clase\n",
        "n_query = 5    # Número de imágenes de consulta por clase\n",
        "\n",
        "# Asigna los datos de entrenamiento (previamente preprocesados)\n",
        "train_x = trainx\n",
        "train_y = trainy\n",
        "\n",
        "# Define parámetros para el proceso de entrenamiento\n",
        "max_epoch = 5       # Número máximo de épocas de entrenamiento\n",
        "epoch_size = 2000   # Número de episodios por época\n",
        "\n",
        "# Itera sobre cada \"n_way\" en la lista n_ways\n",
        "for n_way in n_ways:\n",
        "    # Define un nombre único para el modelo basado en \"n_way\" y \"n_support\"\n",
        "    model_name = f'model{n_way}w{n_support}s'\n",
        "\n",
        "    # Crea un nuevo modelo y define el optimizador Adam\n",
        "    model = create_model()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    # Entrena el modelo con los parámetros actuales\n",
        "    accuracy = train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size)\n",
        "\n",
        "    # Guarda el modelo entrenado en el disco\n",
        "    model.save(f'{model_name}.h5')\n",
        "\n",
        "    # Imprime información sobre el modelo entrenado\n",
        "    print(f'Model {model_name} saved with accuracy {accuracy}')\n"
      ],
      "metadata": {
        "id": "4VnWYmaSYexF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_x, test_y, n_way, n_support, n_query, episodio_test):\n",
        "    \"\"\"\n",
        "    Prueba el rendimiento del modelo entrenado en tareas de clasificación prototípica.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo previamente entrenado.\n",
        "        test_x (np.array): Conjunto de imágenes para prueba.\n",
        "        test_y (np.array): Etiquetas asociadas a las imágenes de prueba.\n",
        "        n_way (int): Número de clases diferentes consideradas en cada tarea de clasificación.\n",
        "        n_support (int): Número de imágenes de soporte por clase.\n",
        "        n_query (int): Número de imágenes de consulta por clase que el modelo deberá clasificar.\n",
        "        episodio_test (int): Número total de episodios/tareas que se ejecutarán para la prueba.\n",
        "\n",
        "    Returns:\n",
        "        float: Precisión promedio obtenida en todos los episodios de prueba.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializa las métricas que almacenarán la suma de las pérdidas y precisiones a lo largo de los episodios.\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "\n",
        "    # Itera a través de cada episodio de prueba.\n",
        "    for episodio in tnrange(episodio_test):\n",
        "        # Genera una nueva tarea de clasificación con clases y ejemplos aleatorios.\n",
        "        muestra = crea_muestra(n_way, n_support, n_query, test_x, test_y)\n",
        "\n",
        "        # Usa la función Proto para obtener la pérdida y las predicciones del modelo.\n",
        "        loss, target_inds_onehot, log_p_y  = Proto(muestra, n_way, n_support, n_query, model)\n",
        "\n",
        "        # Calcula la precisión del modelo en el episodio actual.\n",
        "        accuracy = accuracyProt(target_inds_onehot, log_p_y, n_way, n_query)\n",
        "\n",
        "        # Actualiza las métricas acumulativas.\n",
        "        running_loss += loss\n",
        "        running_acc += accuracy\n",
        "\n",
        "    # Calcula las métricas promedio.\n",
        "    avg_loss = running_loss / episodio_test\n",
        "    avg_acc = running_acc / episodio_test\n",
        "\n",
        "    # Imprime las métricas promedio.\n",
        "    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))\n",
        "\n",
        "    return avg_acc\n"
      ],
      "metadata": {
        "id": "vQgBhpiNYevG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definición de parámetros para pruebas.\n",
        "n_ways_test = [5]      # Número de clases en las tareas de clasificación. (El codigo se deja preparado para hacer más de un n-way a la vez)\n",
        "n_support = 5          # Número de imágenes de soporte por clase.\n",
        "n_query = 5            # Número de imágenes de consulta por clase.\n",
        "test_episode = 1000    # Número total de episodios/tareas de prueba.\n",
        "\n",
        "# Lista para almacenar las precisiones de los modelos durante las pruebas.\n",
        "test_accuracies = []\n",
        "\n",
        "# Itera a través de cada valor en 'n_ways_test' para probar el modelo en diferentes configuraciones de clases.\n",
        "for n_way in n_ways_test:\n",
        "    # Nombre del modelo que será cargado. En este caso, se espera que el modelo 'model60w5sOmniglot.h5' exista.\n",
        "    model_name = f'model60w5sOmniglot.h5'\n",
        "\n",
        "    # Carga el modelo previamente entrenado.\n",
        "    model = load_model(model_name)\n",
        "\n",
        "    # Usa la función 'test' previamente definida para evaluar el rendimiento del modelo en la tarea de clasificación prototípica.\n",
        "    accuracy = test(model, testx, testy, n_way, n_support, n_query, test_episode)\n",
        "\n",
        "    # Agrega la precisión obtenida a la lista 'test_accuracies'.\n",
        "    test_accuracies.append(accuracy)\n",
        "\n",
        "    # Imprime el resultado de la prueba para este modelo.\n",
        "    print(f'Model {model_name} tested with accuracy {accuracy}')\n"
      ],
      "metadata": {
        "id": "tsj47w_3atFU"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}