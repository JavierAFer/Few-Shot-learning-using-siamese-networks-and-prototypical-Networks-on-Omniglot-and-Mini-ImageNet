{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2gAg1Hyl0bd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import multiprocessing as mp\n",
        "import os\n",
        "import cv2\n",
        "from scipy import ndimage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tqdm import tnrange\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lee_alfabetos(ruta_al_directorio_del_alfabeto, nombre_del_alfabeto, max_imagenes=20):\n",
        "    \"\"\"\n",
        "    Lee las primeras 'max_imagenes' imágenes de los alfabetos que contenga el directorio dado.\n",
        "    \"\"\"\n",
        "    datax = []  # Lista para almacenar las imágenes\n",
        "    datay = []  # Lista para almacenar las etiquetas de las imágenes\n",
        "\n",
        "    # Lista todas las imágenes disponibles en el directorio del alfabeto\n",
        "    imagenes = os.listdir(ruta_al_directorio_del_alfabeto)\n",
        "\n",
        "    # Si no hay suficientes imágenes en el directorio, se retorna un mensaje\n",
        "    if len(imagenes) < max_imagenes:\n",
        "        return None, f\"{nombre_del_alfabeto} ({len(imagenes)} imágenes disponibles)\"\n",
        "\n",
        "    # Selecciona las primeras 'max_imagenes' imágenes\n",
        "    imagenes = imagenes[:max_imagenes]\n",
        "\n",
        "    # Procesa cada imagen individualmente\n",
        "    for img in imagenes:\n",
        "        # Carga la imagen\n",
        "        imagen = cv2.imread(os.path.join(ruta_al_directorio_del_alfabeto, img))\n",
        "\n",
        "        # Rota la imagen a diferentes ángulos (90, 180, 270 grados)\n",
        "        rotada_90 = ndimage.rotate(imagen, 90)\n",
        "        rotada_180 = ndimage.rotate(imagen, 180)\n",
        "        rotada_270 = ndimage.rotate(imagen, 270)\n",
        "\n",
        "        # Agrega la imagen original y sus rotaciones a 'datax'\n",
        "        datax.extend((imagen, rotada_90, rotada_180, rotada_270))\n",
        "\n",
        "        # Agrega etiquetas para cada imagen en 'datay'\n",
        "        datay.extend((\n",
        "            ruta_al_directorio_del_alfabeto + '_' + '_0',\n",
        "            ruta_al_directorio_del_alfabeto + '_' + '_90',\n",
        "            ruta_al_directorio_del_alfabeto + '_' + '_180',\n",
        "            ruta_al_directorio_del_alfabeto + '_' + '_270'\n",
        "        ))\n",
        "\n",
        "    # Convierte las listas en arrays de numpy para su manipulación posterior\n",
        "    return np.array(datax), np.array(datay)\n",
        "\n",
        "def preproces_Mini_ImageNet(directorio_principal, max_imagenes_por_clase=600):\n",
        "    \"\"\"\n",
        "    Llama a la función lee_alfabetos para leer las primeras 'max_imagenes_per_class' imágenes de cada uno de los alfabetos del directorio principal.\n",
        "    Si no hay suficientes imágenes en una clase, se incluirá un mensaje en los resultados.\n",
        "    \"\"\"\n",
        "    datax = np.zeros((20, 84, 84, 3))  # Array inicial para almacenar las imágenes\n",
        "    datay = []  # Lista para almacenar las etiquetas\n",
        "\n",
        "    # Utiliza múltiples procesos para leer imágenes en paralelo\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "\n",
        "    # Llama a la función 'lee_alfabetos' para cada directorio en el directorio principal\n",
        "    resultados = [pool.apply(lee_alfabetos,\n",
        "                             args=(\n",
        "                                 os.path.join(directorio_principal, directorio) + '/',\n",
        "                                 directorio,\n",
        "                                 max_imagenes_por_clase\n",
        "                             )) for directorio in os.listdir(directorio_principal)]\n",
        "\n",
        "    # Cierra el pool de procesos\n",
        "    pool.close()\n",
        "\n",
        "    # Procesa los resultados obtenidos\n",
        "    for resultado in resultados:\n",
        "        if resultado[0] is not None:\n",
        "            # Si 'datax' sigue siendo un array inicial (todos ceros), lo reemplaza con el nuevo resultado\n",
        "            if datax.shape == (20, 84, 84, 3) and np.all(datax == 0):\n",
        "                datax = resultado[0]\n",
        "                datay = resultado[1]\n",
        "            else:\n",
        "                # Si no, concatena los resultados\n",
        "                datax = np.vstack([datax, resultado[0]])\n",
        "                datay = np.concatenate([datay, resultado[1]])\n",
        "        else:\n",
        "            # Si no hay suficientes imágenes para un alfabeto, imprime el mensaje\n",
        "            print(resultado[1])\n",
        "\n",
        "    return datax, datay\n"
      ],
      "metadata": {
        "id": "mMbNdisr3xlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprimir los archivos de train, validacion y test\n",
        "!tar -xf train.tar\n",
        "!tar -xf val.tar\n",
        "!tar -xf test.tar"
      ],
      "metadata": {
        "id": "tMbUN9zqmAso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar las imágenes de Mini-ImageNet y guardarlas en sus respectivas variables\n",
        "trainx, trainy = preproces_Mini_ImageNet('train')\n",
        "valx, valy = preproces_Mini_ImageNet('val')\n",
        "testx, testy = preproces_Mini_ImageNet('test')\n",
        "\n",
        "# Como no se va a hacer validación se pueden usar estas imágenes para entrenar.\n",
        "# Aun así en el estudio del trabajo no se realiza este paso. Se pueden comentar estas lineas para no hacerlo.\n",
        "trainx = np.concatenate((trainx, valx), axis=0)\n",
        "trainy=np.concatenate((trainy, valy))"
      ],
      "metadata": {
        "id": "OJEQZFxLmI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainx.shape, trainy.shape, testx.shape, testy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBU94_ptmbQa",
        "outputId": "0605fb69-c5c5-4282-e6c4-bbd408398a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((192000, 84, 84, 3), (192000,), (48000, 84, 84, 3), (48000,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_muestra(n_way, n_support, n_query, datax, datay):\n",
        "    \"\"\"\n",
        "    Crea una muestra aleatoria de tamaño n_support+n_query, de imágenes de n_way clases.\n",
        "\n",
        "    Entrada:\n",
        "        n_way (int): número de clases\n",
        "        n_support (int): número de imágenes en el conjunto soporte por clase\n",
        "        n_query (int): número de imágenes para clasificar por clase\n",
        "        datax (np.array): conjunto de imágenes\n",
        "        datay (np.array): conjunto de etiquetas\n",
        "    Salida:\n",
        "        (dict) de:\n",
        "            (tf.Tensor): Muestra de imágenes de tamaño (n_way, n_support+n_query, (dim))\n",
        "            (int): n_way\n",
        "            (int): n_support\n",
        "            (int): n_query\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtiene las clases únicas presentes en las etiquetas\n",
        "    clases_unicas = np.unique(datay)\n",
        "\n",
        "    # Elige aleatoriamente 'n_way' clases únicas\n",
        "    clases_elegidas = np.random.choice(clases_unicas, n_way, replace=False)\n",
        "\n",
        "    # Suma el número de imágenes de soporte y consulta por clase\n",
        "    ejemplos_por_clase = n_support + n_query\n",
        "\n",
        "    # Crea un array con índices de todas las etiquetas\n",
        "    indices = np.arange(len(datay))\n",
        "\n",
        "    muestra = []\n",
        "\n",
        "    # Para cada clase elegida:\n",
        "    for clase in clases_elegidas:\n",
        "        # Obtiene los índices donde la clase actual está presente en las etiquetas\n",
        "        indices_clase = indices[datay == clase]\n",
        "\n",
        "        # Elige aleatoriamente 'ejemplos_por_clase' índices de esa clase\n",
        "        indices_seleccionados = np.random.choice(indices_clase, ejemplos_por_clase, replace=False)\n",
        "\n",
        "        # Agrega los ejemplos seleccionados a la muestra\n",
        "        muestra.append(datax[indices_seleccionados])\n",
        "\n",
        "    # Convierte la lista de muestras en un tensor de TensorFlow\n",
        "    muestra = tf.convert_to_tensor(np.array(muestra), dtype=tf.float32)\n",
        "\n",
        "    # Retorna un diccionario con la muestra, n_way, n_support y n_query\n",
        "    return {\n",
        "        'imagenes': muestra,\n",
        "        'n_way': n_way,\n",
        "        'n_support': n_support,\n",
        "        'n_query': n_query\n",
        "    }\n"
      ],
      "metadata": {
        "id": "STBWUsRS5RLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def red_convolucional(tamaño_entrada, dimension_caracteristicas):\n",
        "    \"\"\"\n",
        "    Construye y devuelve un modelo de red neuronal convolucional con el tamaño de entrada y\n",
        "    dimensión de características especificados.\n",
        "\n",
        "    Entrada:\n",
        "        tamaño_entrada (tuple): Dimensiones de entrada de la imagen, por ejemplo: (alto, ancho, canales).\n",
        "        dimension_caracteristicas (int): Número de nodos en la última capa densa.\n",
        "\n",
        "    Salida:\n",
        "        (tf.keras.Sequential): Modelo de red convolucional.\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializa un modelo secuencial\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Agrega la primera capa convolucional\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same', input_shape=tamaño_entrada))  # Convolución con 64 filtros de tamaño 3x3\n",
        "    model.add(layers.BatchNormalization())  # Normalización por lotes\n",
        "    model.add(layers.ReLU())  # Función de activación ReLU\n",
        "    model.add(layers.MaxPooling2D((2, 2)))  # Pooling para reducir dimensiones\n",
        "\n",
        "    # Agrega 3 bloques de capas convolucionales más, sin indicar para estos el input_shape\n",
        "    for _ in range(3):\n",
        "        model.add(layers.Conv2D(64, (3, 3), padding='same'))  # Convolución con 64 filtros de tamaño 3x3\n",
        "        model.add(layers.BatchNormalization())  # Normalización por lotes\n",
        "        model.add(layers.ReLU())  # Función de activación ReLU\n",
        "        model.add(layers.MaxPooling2D((2, 2)))  # Pooling para reducir dimensiones\n",
        "\n",
        "    # Convierte la salida de la última capa de pooling a un vector 1D\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Agrega una capa densa con \"dimension_caracteristicas\" nodos\n",
        "    model.add(layers.Dense(dimension_caracteristicas))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "H15Vbsd6mbKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_dist(x, y):\n",
        "    \"\"\"\n",
        "    Calcula la distancia euclidea al cuadrado entre x e y.\n",
        "\n",
        "    Entrada:\n",
        "        x (tf.Tensor): tamaño (n, d). n es n_way*n_query.\n",
        "        y (tf.Tensor): tamaño (m, d). m es n_way.\n",
        "\n",
        "    Salida:\n",
        "        tf.Tensor: tamaño (n, m). Para cada imagen de consulta, las distancias a cada uno de los prototipos.\n",
        "    \"\"\"\n",
        "\n",
        "    # Obtener las dimensiones de los tensores x e y\n",
        "    n = tf.shape(x)[0]  # Número de filas de x\n",
        "    m = tf.shape(y)[0]  # Número de filas de y\n",
        "    d = tf.shape(x)[1]  # Número de columnas de x, que debería ser igual al número de columnas de y\n",
        "\n",
        "    # Expande las dimensiones de x para que se pueda difundir (broadcast) contra y\n",
        "    x = tf.expand_dims(x, 1)   # Añade una nueva dimensión en el índice 1\n",
        "    x = tf.tile(x, (1, m, 1))  # Repite x m veces a lo largo de la nueva dimensión creada\n",
        "\n",
        "    # Expande las dimensiones de y para que se pueda difundir (broadcast) contra x\n",
        "    y = tf.expand_dims(y, 0)   # Añade una nueva dimensión en el índice 0\n",
        "    y = tf.tile(y, (n, 1, 1))  # Repite y n veces a lo largo de la nueva dimensión creada\n",
        "\n",
        "    # Calcula la distancia euclidiana al cuadrado entre x e y\n",
        "    # Reduce a lo largo del eje 2 (dimensión d) después de calcular el cuadrado de las diferencias\n",
        "    return tf.reduce_sum(tf.square(x - y), axis=2)\n"
      ],
      "metadata": {
        "id": "zZ8oYtewmbIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def floss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calcula la función de pérdida personalizada para dos vectores: uno que contiene las etiquetas verdaderas y\n",
        "    otro que contiene las probabilidades predichas de las clases.\n",
        "\n",
        "    Entrada:\n",
        "        y_true (tf.Tensor): Tensor que contiene las etiquetas verdaderas en formato one-hot encoding.\n",
        "        y_pred (tf.Tensor): Tensor que contiene las probabilidades predichas de las clases.\n",
        "\n",
        "    Salida:\n",
        "        tf.Tensor: Un valor escalar que representa la pérdida calculada.\n",
        "    \"\"\"\n",
        "\n",
        "    # Multiplica elemento a elemento las etiquetas verdaderas con las probabilidades predichas\n",
        "    # Luego, sumamos esos valores a lo largo del último eje (axis=-1)\n",
        "    # Finalmente, calculamos el negativo de la media de esos valores sumados\n",
        "\n",
        "    loss_val = -tf.reduce_mean(tf.reduce_sum(y_true * y_pred, axis=-1))\n",
        "\n",
        "    return loss_val\n"
      ],
      "metadata": {
        "id": "FW62AlrGmbGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracyProt(y_true, y_pred, n_way, n_query):\n",
        "    \"\"\"\n",
        "    Calcula la precisión de las predicciones basándose en etiquetas verdaderas y predicciones.\n",
        "\n",
        "    Entrada:\n",
        "        y_true (tf.Tensor): Tensor que contiene las etiquetas verdaderas en formato one-hot encoding.\n",
        "        y_pred (tf.Tensor): Tensor que contiene las probabilidades predichas de las clases.\n",
        "        n_way (int): Número de clases únicas.\n",
        "        n_query (int): Número de imágenes para clasificar por clase.\n",
        "\n",
        "    Salida:\n",
        "        float: Precisión de las predicciones.\n",
        "    \"\"\"\n",
        "\n",
        "    # Encuentra el índice del valor máximo en y_pred a lo largo del eje 1\n",
        "    # Esto nos dará la clase predicha para cada muestra.\n",
        "    predicciones = tf.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Encuentra el índice del valor máximo en y_true a lo largo del eje 1\n",
        "    # Esto nos dará la etiqueta verdadera para cada muestra.\n",
        "    etiquetas_correctas = tf.argmax(y_true, axis=1)\n",
        "\n",
        "    # Compara las predicciones con las etiquetas correctas y cuenta cuántas coinciden.\n",
        "    total_correct = tf.reduce_sum(tf.cast(tf.equal(predicciones, etiquetas_correctas), tf.int32))\n",
        "\n",
        "    # Calcula la precisión dividiendo el número total de predicciones correctas\n",
        "    # por el número total de predicciones (n_way * n_query).\n",
        "    accuracyp = total_correct / (n_way * n_query)\n",
        "\n",
        "    return accuracyp\n"
      ],
      "metadata": {
        "id": "vBunDtwhmakN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Proto(sample, n_way, n_support, n_query, model):\n",
        "    \"\"\"\n",
        "    Implementa el Prototipo de redes para el aprendizaje de pocas tomas.\n",
        "\n",
        "    Entrada:\n",
        "        sample (dict): Diccionario que contiene las imágenes.\n",
        "        n_way (int): Número de clases únicas.\n",
        "        n_support (int): Número de imágenes de soporte por clase.\n",
        "        n_query (int): Número de imágenes de consulta por clase.\n",
        "        model (tf.keras.Model): Modelo de red neuronal para extraer características.\n",
        "\n",
        "    Salida:\n",
        "        loss (tf.Tensor): Valor de la función de pérdida calculada.\n",
        "        target_inds_onehot (tf.Tensor): Etiquetas verdaderas en formato one-hot encoding.\n",
        "        log_p_y (tf.Tensor): Log-probabilidades predichas.\n",
        "    \"\"\"\n",
        "\n",
        "    # Separa las imágenes de soporte y consulta del diccionario 'sample'\n",
        "    x_support = sample['imagenes'][:, :n_support]\n",
        "    x_query = sample['imagenes'][:, n_support:]\n",
        "\n",
        "    # Reajusta las dimensiones de las imágenes de soporte y consulta\n",
        "    x_support = np.reshape(x_support, (x_support.shape[0] * x_support.shape[1], *x_support.shape[2:]))\n",
        "    x_query = np.reshape(x_query, (x_query.shape[0] * x_query.shape[1], *x_query.shape[2:]))\n",
        "\n",
        "    # Convierte las imágenes a tensores y normaliza sus valores (0-255 a 0-1)\n",
        "    x_support = tf.convert_to_tensor(x_support / 255.0, dtype=tf.float32)\n",
        "    x_query = tf.convert_to_tensor(x_query / 255.0, dtype=tf.float32)\n",
        "\n",
        "    # Genera las etiquetas verdaderas para las imágenes de consulta en formato one-hot\n",
        "    target_inds = [i // n_query for i in range(n_way * n_query)]\n",
        "    target_inds_onehot = tf.keras.utils.to_categorical(target_inds, num_classes=n_way)\n",
        "    target_inds_onehot = tf.convert_to_tensor(target_inds_onehot)\n",
        "\n",
        "    # Usa el modelo para extraer las características de las imágenes de soporte y consulta\n",
        "    z_support = model(x_support)\n",
        "    z_query = model(x_query)\n",
        "\n",
        "    # Calcula el prototipo (representación promedio) para cada clase a partir de las características de soporte\n",
        "    z_proto = tf.reduce_mean(tf.reshape(z_support, (n_way, n_support, -1)), axis=1)\n",
        "\n",
        "    # Calcula la distancia euclídea entre las características de consulta y los prototipos\n",
        "    dists = euclidean_dist(z_query, z_proto)\n",
        "\n",
        "    # Calcula las log-probabilidades predichas a partir de las distancias\n",
        "    log_p_y = tf.nn.log_softmax(-dists, axis=1)\n",
        "\n",
        "    # Calcula la función de pérdida usando las etiquetas verdaderas y las log-probabilidades predichas\n",
        "    loss = floss(target_inds_onehot, log_p_y)\n",
        "\n",
        "    return loss, target_inds_onehot, log_p_y\n"
      ],
      "metadata": {
        "id": "R0CVbBVxnYS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epocas, tamaño_epoca):\n",
        "    \"\"\"\n",
        "    Entrena el modelo utilizando una red prototipica.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): Modelo de la red convolucional a entrenar.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Optimizador a utilizar.\n",
        "        train_x (np.array): Imágenes del conjunto de entrenamiento.\n",
        "        train_y (np.array): Etiquetas del conjunto de entrenamiento.\n",
        "        n_way (int): Número de clases diferentes para la clasificación.\n",
        "        n_support (int): Número de ejemplos de soporte por clase.\n",
        "        n_query (int): Número de ejemplos de consulta por clase.\n",
        "        max_epocas (int): Número máximo de épocas de entrenamiento.\n",
        "        tamaño_epoca (int): Número de episodios por época.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define el plan de ajuste para el learning rate\n",
        "    scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        0.001, decay_steps=2000, decay_rate=0.5, staircase=True)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
        "\n",
        "    # Listas para almacenar los valores de pérdida y precisión parcial para cada época\n",
        "    loss_parcial = []\n",
        "    acc_parcial = []\n",
        "\n",
        "    for epoca in range(max_epocas):\n",
        "        # Inicialización de la pérdida y precisión para cada época\n",
        "        loss_actual = 0.0\n",
        "        acc_actual = 0.0\n",
        "\n",
        "        for episodio in tnrange(tamaño_epoca):\n",
        "            # Registra las operaciones para las cuales se calcularán los gradientes\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Crea una muestra aleatoria optimizada\n",
        "                sample = crea_muestra(n_way, n_support, n_query, train_x, train_y)\n",
        "                # Calcula la pérdida y las log-probabilidades usando la función Proto\n",
        "                loss, target_inds_onehot, log_p_y = Proto(sample, n_way, n_support, n_query, model)\n",
        "                # Calcula los gradientes\n",
        "                gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                # Aplica los gradientes para actualizar el modelo\n",
        "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "            # Calcula la precisión para este episodio\n",
        "            accuracy = accuracyProt(target_inds_onehot, log_p_y, n_way, n_query)\n",
        "            # Acumula la pérdida y precisión\n",
        "            loss_actual += loss\n",
        "            acc_actual += accuracy\n",
        "\n",
        "            # Guarda la pérdida y precisión media cada 500 episodios\n",
        "            if (episodio + 1) % 500 == 0:\n",
        "                loss_parcial.append(loss_actual / 500)\n",
        "                acc_parcial.append(acc_actual / 500)\n",
        "                loss_actual = 0.0  # resetea la pérdida acumulada\n",
        "                acc_actual = 0.0   # resetea la precisión acumulada\n",
        "\n",
        "        # Calcula la pérdida y precisión media de la época y la imprime\n",
        "        loss_epoca = sum(loss_parcial[-(tamaño_epoca // 500):]) / (tamaño_epoca // 500)\n",
        "        acc_epoca = sum(acc_parcial[-(tamaño_epoca // 500):]) / (tamaño_epoca // 500)\n",
        "        print(f'Epoch {epoca + 1} -- Loss: {loss_epoca:.4f} Acc: {acc_epoca:.4f}')\n",
        "\n",
        "    return loss_parcial, acc_parcial\n",
        "\n"
      ],
      "metadata": {
        "id": "ibvbFppJnYQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crea_modelo():\n",
        "    return red_convolucional((84, 84, 3), 256)"
      ],
      "metadata": {
        "id": "hnTA8LWDnYPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define las configuraciones de entrenamiento\n",
        "n_ways = [60]           # Lista de diferentes valores de 'n_way' a probar\n",
        "n_support = 5           # Número de ejemplos de soporte por clase\n",
        "n_query = 5             # Número de ejemplos de consulta por clase\n",
        "\n",
        "train_x = trainx        # Conjunto de entrenamiento de imágenes\n",
        "train_y = trainy        # Etiquetas del conjunto de entrenamiento\n",
        "\n",
        "max_epocas = 10         # Número máximo de épocas de entrenamiento\n",
        "tamaño_epoca = 2000     # Número de episodios por época\n",
        "\n",
        "# Loop a través de diferentes configuraciones 'n_way'\n",
        "for n_way in n_ways:\n",
        "    # Crea un nombre único para cada configuración de modelo\n",
        "    model_name = f'modelProImag{n_way}w{n_support}s2'\n",
        "\n",
        "    # Crea un nuevo modelo prototípico para esta configuración\n",
        "    model = crea_modelo()\n",
        "\n",
        "    # Define el optimizador para el entrenamiento\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    # Entrena el modelo con la configuración actual de 'n_way'\n",
        "    loss, acc = train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epocas, tamaño_epoca)\n",
        "\n",
        "    # Guarda el modelo entrenado en el disco\n",
        "    model.save(f'{model_name}.h5')\n"
      ],
      "metadata": {
        "id": "tPAj2jH6nYNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, test_x, test_y, n_way, n_support, n_query, episodios_test):\n",
        "    \"\"\"\n",
        "    Prueba el modelo prototypical\n",
        "    Args:\n",
        "        model: modelo entrenado\n",
        "        test_x (np.array): imágenes del conjunto de prueba\n",
        "        test_y (np.array): etiquetas del conjunto de prueba\n",
        "        n_way (int): número de clases en una tarea de clasificación\n",
        "        n_support (int): número de ejemplos etiquetados por clase en el conjunto de soporte\n",
        "        n_query (int): número de ejemplos etiquetados por clase en el conjunto de consulta\n",
        "        episodios_test (int): número de episodios para probar\n",
        "    \"\"\"\n",
        "\n",
        "    # Inicializar las métricas de pérdida y precisión\n",
        "    loss_actual = 0.0\n",
        "    acc_actual = 0.0\n",
        "\n",
        "    # Iterar a través de cada episodio de prueba\n",
        "    for episode in tnrange(episodios_test):\n",
        "        # Crear una muestra optimizada a partir del conjunto de prueba\n",
        "        sample = crea_muestra(n_way, n_support, n_query, test_x, test_y)\n",
        "\n",
        "        # Calcular la pérdida y las probabilidades logarítmicas con la función Proto\n",
        "        loss, target_inds_onehot, log_p_y  = Proto(sample, n_way, n_support, n_query, model)\n",
        "\n",
        "        # Calcular la precisión del modelo en esta muestra\n",
        "        accuracy = accuracyProt(target_inds_onehot, log_p_y, n_way, n_query)\n",
        "\n",
        "        # Acumular la pérdida y la precisión para calcular el promedio posteriormente\n",
        "        loss_actual += loss\n",
        "        acc_actual += accuracy\n",
        "\n",
        "    # Calcular las métricas promedio a lo largo de todos los episodios de prueba\n",
        "    avg_loss = loss_actual / episodios_test\n",
        "    avg_acc = acc_actual / episodios_test\n",
        "\n",
        "    # Imprimir los resultados de la prueba\n",
        "    print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))\n",
        "\n",
        "    # Devolver la precisión promedio\n",
        "    return avg_acc\n"
      ],
      "metadata": {
        "id": "rYgXxGw7nYLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define los parámetros de prueba:\n",
        "# n_ways_test: Lista que contiene el número de clases que se utilizarán en las tareas de prueba.\n",
        "# n_support: Número de ejemplos etiquetados por clase en el conjunto de soporte.\n",
        "# n_query: Número de ejemplos etiquetados por clase en el conjunto de consulta.\n",
        "# test_episode: Número total de episodios para realizar pruebas.\n",
        "\n",
        "n_ways_test = [5] #La lista se puede ampliarse con el resto de n-ways que se quieran probar\n",
        "n_support = 5 # 5-shot, se puede cambiar a 1-shot\n",
        "n_query = 5 # 5 imagenes de prueba por cada clase.\n",
        "episodios_test = 500\n",
        "\n",
        "# Itera a través de cada valor de 'n_way' en la lista 'n_ways_test'\n",
        "for n_way in n_ways_test:\n",
        "    # Define el nombre del archivo del modelo previamente entrenado para cargarlo (el modelo debe tener el mismo nombre)\n",
        "    nombre_modelo = f'modelProImag60w5s.h5'\n",
        "\n",
        "    # # Carga el modelo con el nombre definido\n",
        "    model = load_model(nombre_modelo)\n",
        "\n",
        "    # Realiza pruebas en el modelo cargado usando los parámetros definidos y el conjunto de datos de prueba (testx y testy)\n",
        "    accuracy = test(model, testx, testy, n_way, n_support, n_query, episodios_test)\n",
        "\n",
        "    # Imprime la precisión obtenida en la prueba\n",
        "    print(f'Model {nombre_modelo} tested with accuracy {accuracy}')\n"
      ],
      "metadata": {
        "id": "51QzJRHanYJC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}